{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_processing_task1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpb6BVJdO9avEtqSOfkIrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maysis175/text-processing/blob/master/text_processing_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abKiB3fDcQKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "0245e967-27b2-46a3-927a-a934d88cf0e2"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xGFdjHEcYBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liBEiIW_cerX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "763e28f2-dbd5-46a6-a1c9-befb269eb501"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAT2pVY0rNPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wikipediaより，10人の数学者の項目の冒頭を抜粋\n",
        "documents = [\"Leonhard Euler (15 April 1707 – 18 September 1783) was a Swiss mathematician, physicist, astronomer, geographer, logician and engineer who made important and influential discoveries in many branches of mathematics, such as infinitesimal calculus and graph theory, while also making pioneering contributions to several branches such as topology and analytic number theory.\",\n",
        "             \"Pierre de Fermat (between 20 August 1601[1] – 12 January 1665) was a French lawyer[3] at the Parlement of Toulouse, France, and a mathematician who is given credit for early developments that led to infinitesimal calculus, including his technique of adequality.\",\n",
        "             \"Blaise Pascal (19 June 1623 – 19 August 1662) was a French mathematician, physicist, inventor, writer and Catholic theologian. He was a child prodigy who was educated by his father, a tax collector in Rouen. Pascal's earliest work was in the natural and applied sciences, where he made important contributions to the study of fluids, and clarified the concepts of pressure and vacuum by generalising the work of Evangelista Torricelli. Pascal also wrote in defence of the scientific method.\",\n",
        "             \"René Descartes (31 March 1596 – 11 February 1650)[16][17][18][19] was a French philosopher, mathematician, and scientist. A native of the Kingdom of France, he spent about 20 years (1629–1649) of his life in the Dutch Republic after serving for a while in the Dutch States Army of Maurice of Nassau, Prince of Orange and the Stadtholder of the United Provinces. One of the most notable intellectual figures of the Dutch Golden Age,[20] Descartes is also widely regarded as one of the founders of modern philosophy.\",\n",
        "             \"Kurt Friedrich Gödel (April 28, 1906 – January 14, 1978) was an Austro-Hungarian-born Austrian logician, mathematician, and analytic philosopher. Considered along with Aristotle and Gottlob Frege to be one of the most significant logicians in history, Gödel had an immense effect upon scientific and philosophical thinking in the 20th century, a time when others such as Bertrand Russell,[3] Alfred North Whitehead,[3] and David Hilbert were analyzing the use of logic and set theory to understand the foundations of mathematics pioneered by Georg Cantor.\",\n",
        "             \"Srinivasa Ramanujan FRS (born Srinivasa Ramanujan Aiyangar; 22 December 1887 – 26 April 1920)[2][3] was an Indian mathematician who lived during the British Rule in India. Though he had almost no formal training in pure mathematics, he made substantial contributions to mathematical analysis, number theory, infinite series, and continued fractions, including solutions to mathematical problems then considered unsolvable. \",\n",
        "             \"Johann Carl Friedrich Gauss (Latin: Carolus Fridericus Gauss; 30 April 1777 – 23 February 1855) was a German mathematician and physicist who made significant contributions to many fields in mathematics and science.[3] Sometimes referred to as the Princeps mathematicorum[4] (Latin for 'the foremost of mathematicians') and the greatest mathematician since antiquity, Gauss had an exceptional influence in many fields of mathematics and science, and is ranked among history's most influential mathematicians.[5]\",\n",
        "             \"Paul Erdős (26 March 1913 – 20 September 1996) was a renowned Hungarian mathematician. He was one of the most prolific mathematicians and producers of mathematical conjectures[2] of the 20th century.[3] He was known both for his social practice of mathematics (he engaged more than 500 collaborators) and for his eccentric lifestyle (Time magazine called him The Oddball's Oddball).[4] He devoted his waking hours to mathematics, even into his later years—indeed, his death came only hours after he solved a geometry problem at a conference in Warsaw.\",\n",
        "             \"Alexander Grothendieck (28 March 1928 – 13 November 2014) was a mathematician who became the leading figure in the creation of modern algebraic geometry.[7][8] His research extended the scope of the field and added elements of commutative algebra, homological algebra, sheaf theory and category theory to its foundations, while his so-called relative perspective led to revolutionary advances in many areas of pure mathematics.[7][9] He is considered by many to be the greatest mathematician of the 20th century.[10]\",\n",
        "             \"Évariste Galois (25 October 1811 – 31 May 1832) was a French mathematician and political activist. While still in his teens, he was able to determine a necessary and sufficient condition for a polynomial to be solvable by radicals, thereby solving a problem standing for 350 years. His work laid the foundations for Galois theory and group theory,[2] two major branches of abstract algebra, and the subfield of Galois connections. He died at age 20 from wounds suffered in a duel.[3]\"]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92nX3BlozTbP",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2NGUMPtYjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning\n",
        "import re\n",
        "\n",
        "def cleaning_text(text): \n",
        "    # ()内を削除\n",
        "    pattern3 = \"\\(.*?\\)\"\n",
        "    text = re.sub(pattern3, '', text) \n",
        "    # []内を削除\n",
        "    pattern2 = \"\\[.*?\\]\"\n",
        "    text = re.sub(pattern2, '', text)\n",
        "    return text "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksRNRNAgw8Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "def tokenize_text(text):\n",
        "  text = re.sub('[.,]', '', text)\n",
        "  return text.split()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMQZqdmxaR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def lemmatize_word(word):\n",
        "  word = word.lower()\n",
        "  lemma = wn.morphy(word)\n",
        "  if lemma is None:\n",
        "    return word\n",
        "  else:\n",
        "    return lemma"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuoyGaqyPTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(word, stopwordset):\n",
        "  if word in stopwordset:\n",
        "    return None\n",
        "  else:\n",
        "    return word"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBpdfHSZxqg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b2b4f2f-da23-4343-b908-729dd58d84dd"
      },
      "source": [
        "# Lemmatize and Remove stop words\n",
        "en_stop = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def preprocessing_text(text):\n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
        "  tokens = [word for word in tokens if word is not None]\n",
        "  return tokens\n",
        "\n",
        "preprocessed_docs = [preprocessing_text(text) for text in documents]\n",
        "preprocessed_docs"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['leonhard',\n",
              "  'euler',\n",
              "  'wa',\n",
              "  'swiss',\n",
              "  'mathematician',\n",
              "  'physicist',\n",
              "  'astronomer',\n",
              "  'geographer',\n",
              "  'logician',\n",
              "  'engineer',\n",
              "  'make',\n",
              "  'important',\n",
              "  'influential',\n",
              "  'discovery',\n",
              "  'many',\n",
              "  'branch',\n",
              "  'mathematics',\n",
              "  'infinitesimal',\n",
              "  'calculus',\n",
              "  'graph',\n",
              "  'theory',\n",
              "  'also',\n",
              "  'making',\n",
              "  'pioneer',\n",
              "  'contribution',\n",
              "  'several',\n",
              "  'branch',\n",
              "  'topology',\n",
              "  'analytic',\n",
              "  'number',\n",
              "  'theory'],\n",
              " ['pierre',\n",
              "  'de',\n",
              "  'fermat',\n",
              "  'wa',\n",
              "  'french',\n",
              "  'lawyer',\n",
              "  'parlement',\n",
              "  'toulouse',\n",
              "  'france',\n",
              "  'mathematician',\n",
              "  'given',\n",
              "  'credit',\n",
              "  'early',\n",
              "  'development',\n",
              "  'led',\n",
              "  'infinitesimal',\n",
              "  'calculus',\n",
              "  'include',\n",
              "  'technique',\n",
              "  'adequality'],\n",
              " ['blaise',\n",
              "  'pascal',\n",
              "  'wa',\n",
              "  'french',\n",
              "  'mathematician',\n",
              "  'physicist',\n",
              "  'inventor',\n",
              "  'writer',\n",
              "  'catholic',\n",
              "  'theologian',\n",
              "  'wa',\n",
              "  'child',\n",
              "  'prodigy',\n",
              "  'wa',\n",
              "  'educate',\n",
              "  'father',\n",
              "  'tax',\n",
              "  'collector',\n",
              "  'rouen',\n",
              "  \"pascal's\",\n",
              "  'earliest',\n",
              "  'work',\n",
              "  'wa',\n",
              "  'natural',\n",
              "  'apply',\n",
              "  'science',\n",
              "  'make',\n",
              "  'important',\n",
              "  'contribution',\n",
              "  'study',\n",
              "  'fluid',\n",
              "  'clarify',\n",
              "  'concept',\n",
              "  'pressure',\n",
              "  'vacuum',\n",
              "  'generalise',\n",
              "  'work',\n",
              "  'evangelista',\n",
              "  'torricelli',\n",
              "  'pascal',\n",
              "  'also',\n",
              "  'write',\n",
              "  'defence',\n",
              "  'scientific',\n",
              "  'method'],\n",
              " ['rené',\n",
              "  'descartes',\n",
              "  'wa',\n",
              "  'french',\n",
              "  'philosopher',\n",
              "  'mathematician',\n",
              "  'scientist',\n",
              "  'native',\n",
              "  'kingdom',\n",
              "  'france',\n",
              "  'spend',\n",
              "  '20',\n",
              "  'years',\n",
              "  'life',\n",
              "  'dutch',\n",
              "  'republic',\n",
              "  'serving',\n",
              "  'dutch',\n",
              "  'state',\n",
              "  'army',\n",
              "  'maurice',\n",
              "  'nassau',\n",
              "  'prince',\n",
              "  'orange',\n",
              "  'stadtholder',\n",
              "  'unite',\n",
              "  'province',\n",
              "  'one',\n",
              "  'notable',\n",
              "  'intellectual',\n",
              "  'figure',\n",
              "  'dutch',\n",
              "  'golden',\n",
              "  'age',\n",
              "  'descartes',\n",
              "  'also',\n",
              "  'widely',\n",
              "  'regard',\n",
              "  'one',\n",
              "  'founder',\n",
              "  'modern',\n",
              "  'philosophy'],\n",
              " ['kurt',\n",
              "  'friedrich',\n",
              "  'gödel',\n",
              "  'wa',\n",
              "  'austro-hungarian-born',\n",
              "  'austrian',\n",
              "  'logician',\n",
              "  'mathematician',\n",
              "  'analytic',\n",
              "  'philosopher',\n",
              "  'consider',\n",
              "  'along',\n",
              "  'aristotle',\n",
              "  'gottlob',\n",
              "  'frege',\n",
              "  'one',\n",
              "  'significant',\n",
              "  'logician',\n",
              "  'history',\n",
              "  'gödel',\n",
              "  'immense',\n",
              "  'effect',\n",
              "  'upon',\n",
              "  'scientific',\n",
              "  'philosophical',\n",
              "  'thinking',\n",
              "  '20th',\n",
              "  'century',\n",
              "  'time',\n",
              "  'others',\n",
              "  'bertrand',\n",
              "  'russell',\n",
              "  'alfred',\n",
              "  'north',\n",
              "  'whitehead',\n",
              "  'david',\n",
              "  'hilbert',\n",
              "  'analyze',\n",
              "  'use',\n",
              "  'logic',\n",
              "  'set',\n",
              "  'theory',\n",
              "  'understand',\n",
              "  'foundation',\n",
              "  'mathematics',\n",
              "  'pioneer',\n",
              "  'georg',\n",
              "  'cantor'],\n",
              " ['srinivasa',\n",
              "  'ramanujan',\n",
              "  'frs',\n",
              "  'wa',\n",
              "  'indian',\n",
              "  'mathematician',\n",
              "  'live',\n",
              "  'british',\n",
              "  'rule',\n",
              "  'india',\n",
              "  'though',\n",
              "  'almost',\n",
              "  'formal',\n",
              "  'training',\n",
              "  'pure',\n",
              "  'mathematics',\n",
              "  'make',\n",
              "  'substantial',\n",
              "  'contribution',\n",
              "  'mathematical',\n",
              "  'analysis',\n",
              "  'number',\n",
              "  'theory',\n",
              "  'infinite',\n",
              "  'series',\n",
              "  'continue',\n",
              "  'fraction',\n",
              "  'include',\n",
              "  'solution',\n",
              "  'mathematical',\n",
              "  'problem',\n",
              "  'consider',\n",
              "  'unsolvable'],\n",
              " ['johann',\n",
              "  'carl',\n",
              "  'friedrich',\n",
              "  'gauss',\n",
              "  'wa',\n",
              "  'german',\n",
              "  'mathematician',\n",
              "  'physicist',\n",
              "  'make',\n",
              "  'significant',\n",
              "  'contribution',\n",
              "  'many',\n",
              "  'fields',\n",
              "  'mathematics',\n",
              "  'science',\n",
              "  'sometimes',\n",
              "  'refer',\n",
              "  'princeps',\n",
              "  'mathematicorum',\n",
              "  'greatest',\n",
              "  'mathematician',\n",
              "  'since',\n",
              "  'antiquity',\n",
              "  'gauss',\n",
              "  'exceptional',\n",
              "  'influence',\n",
              "  'many',\n",
              "  'fields',\n",
              "  'mathematics',\n",
              "  'science',\n",
              "  'rank',\n",
              "  'among',\n",
              "  \"history's\",\n",
              "  'influential',\n",
              "  'mathematician'],\n",
              " ['paul',\n",
              "  'erdős',\n",
              "  'wa',\n",
              "  'renowned',\n",
              "  'hungarian',\n",
              "  'mathematician',\n",
              "  'wa',\n",
              "  'one',\n",
              "  'prolific',\n",
              "  'mathematician',\n",
              "  'producer',\n",
              "  'mathematical',\n",
              "  'conjecture',\n",
              "  '20th',\n",
              "  'century',\n",
              "  'wa',\n",
              "  'know',\n",
              "  'social',\n",
              "  'practice',\n",
              "  'mathematics',\n",
              "  'eccentric',\n",
              "  'lifestyle',\n",
              "  'devote',\n",
              "  'waking',\n",
              "  'hours',\n",
              "  'mathematics',\n",
              "  'even',\n",
              "  'later',\n",
              "  'years—indeed',\n",
              "  'death',\n",
              "  'come',\n",
              "  'hours',\n",
              "  'solve',\n",
              "  'geometry',\n",
              "  'problem',\n",
              "  'conference',\n",
              "  'warsaw'],\n",
              " ['alexander',\n",
              "  'grothendieck',\n",
              "  'wa',\n",
              "  'mathematician',\n",
              "  'become',\n",
              "  'leading',\n",
              "  'figure',\n",
              "  'creation',\n",
              "  'modern',\n",
              "  'algebraic',\n",
              "  'geometry',\n",
              "  'research',\n",
              "  'extend',\n",
              "  'scope',\n",
              "  'field',\n",
              "  'add',\n",
              "  'elements',\n",
              "  'commutative',\n",
              "  'algebra',\n",
              "  'homological',\n",
              "  'algebra',\n",
              "  'sheaf',\n",
              "  'theory',\n",
              "  'category',\n",
              "  'theory',\n",
              "  'foundation',\n",
              "  'so-called',\n",
              "  'relative',\n",
              "  'perspective',\n",
              "  'led',\n",
              "  'revolutionary',\n",
              "  'advance',\n",
              "  'many',\n",
              "  'area',\n",
              "  'pure',\n",
              "  'mathematics',\n",
              "  'consider',\n",
              "  'many',\n",
              "  'greatest',\n",
              "  'mathematician',\n",
              "  '20th',\n",
              "  'century'],\n",
              " ['évariste',\n",
              "  'galois',\n",
              "  'wa',\n",
              "  'french',\n",
              "  'mathematician',\n",
              "  'political',\n",
              "  'activist',\n",
              "  'still',\n",
              "  'teens',\n",
              "  'wa',\n",
              "  'able',\n",
              "  'determine',\n",
              "  'necessary',\n",
              "  'sufficient',\n",
              "  'condition',\n",
              "  'polynomial',\n",
              "  'solvable',\n",
              "  'radical',\n",
              "  'thereby',\n",
              "  'solving',\n",
              "  'problem',\n",
              "  'standing',\n",
              "  '350',\n",
              "  'years',\n",
              "  'work',\n",
              "  'lay',\n",
              "  'foundation',\n",
              "  'galois',\n",
              "  'theory',\n",
              "  'group',\n",
              "  'theory',\n",
              "  'two',\n",
              "  'major',\n",
              "  'branch',\n",
              "  'abstract',\n",
              "  'algebra',\n",
              "  'subfield',\n",
              "  'galois',\n",
              "  'connection',\n",
              "  'die',\n",
              "  'age',\n",
              "  '20',\n",
              "  'wound',\n",
              "  'suffer',\n",
              "  'duel']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNEcfawTzZba",
        "colab_type": "text"
      },
      "source": [
        "Vectorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Re9tXLbx3aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "50978d73-3653-4571-e074-e6eb31b3727a"
      },
      "source": [
        "# Bag of Words\n",
        "def bow_vectorizer(docs):\n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "        \n",
        "  result_list = []\n",
        "  for doc in docs:\n",
        "    doc_vec = [0] * len(word2id)\n",
        "    for w in doc:\n",
        "      doc_vec[word2id[w]] += 1\n",
        "    result_list.append(doc_vec)\n",
        "  return result_list, word2id\n",
        "\n",
        "bow_vec, word2id = bow_vectorizer(preprocessed_docs)\n",
        "print(bow_vec)\n",
        "print(word2id.items())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 3, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "dict_items([('leonhard', 0), ('euler', 1), ('wa', 2), ('swiss', 3), ('mathematician', 4), ('physicist', 5), ('astronomer', 6), ('geographer', 7), ('logician', 8), ('engineer', 9), ('make', 10), ('important', 11), ('influential', 12), ('discovery', 13), ('many', 14), ('branch', 15), ('mathematics', 16), ('infinitesimal', 17), ('calculus', 18), ('graph', 19), ('theory', 20), ('also', 21), ('making', 22), ('pioneer', 23), ('contribution', 24), ('several', 25), ('topology', 26), ('analytic', 27), ('number', 28), ('pierre', 29), ('de', 30), ('fermat', 31), ('french', 32), ('lawyer', 33), ('parlement', 34), ('toulouse', 35), ('france', 36), ('given', 37), ('credit', 38), ('early', 39), ('development', 40), ('led', 41), ('include', 42), ('technique', 43), ('adequality', 44), ('blaise', 45), ('pascal', 46), ('inventor', 47), ('writer', 48), ('catholic', 49), ('theologian', 50), ('child', 51), ('prodigy', 52), ('educate', 53), ('father', 54), ('tax', 55), ('collector', 56), ('rouen', 57), (\"pascal's\", 58), ('earliest', 59), ('work', 60), ('natural', 61), ('apply', 62), ('science', 63), ('study', 64), ('fluid', 65), ('clarify', 66), ('concept', 67), ('pressure', 68), ('vacuum', 69), ('generalise', 70), ('evangelista', 71), ('torricelli', 72), ('write', 73), ('defence', 74), ('scientific', 75), ('method', 76), ('rené', 77), ('descartes', 78), ('philosopher', 79), ('scientist', 80), ('native', 81), ('kingdom', 82), ('spend', 83), ('20', 84), ('years', 85), ('life', 86), ('dutch', 87), ('republic', 88), ('serving', 89), ('state', 90), ('army', 91), ('maurice', 92), ('nassau', 93), ('prince', 94), ('orange', 95), ('stadtholder', 96), ('unite', 97), ('province', 98), ('one', 99), ('notable', 100), ('intellectual', 101), ('figure', 102), ('golden', 103), ('age', 104), ('widely', 105), ('regard', 106), ('founder', 107), ('modern', 108), ('philosophy', 109), ('kurt', 110), ('friedrich', 111), ('gödel', 112), ('austro-hungarian-born', 113), ('austrian', 114), ('consider', 115), ('along', 116), ('aristotle', 117), ('gottlob', 118), ('frege', 119), ('significant', 120), ('history', 121), ('immense', 122), ('effect', 123), ('upon', 124), ('philosophical', 125), ('thinking', 126), ('20th', 127), ('century', 128), ('time', 129), ('others', 130), ('bertrand', 131), ('russell', 132), ('alfred', 133), ('north', 134), ('whitehead', 135), ('david', 136), ('hilbert', 137), ('analyze', 138), ('use', 139), ('logic', 140), ('set', 141), ('understand', 142), ('foundation', 143), ('georg', 144), ('cantor', 145), ('srinivasa', 146), ('ramanujan', 147), ('frs', 148), ('indian', 149), ('live', 150), ('british', 151), ('rule', 152), ('india', 153), ('though', 154), ('almost', 155), ('formal', 156), ('training', 157), ('pure', 158), ('substantial', 159), ('mathematical', 160), ('analysis', 161), ('infinite', 162), ('series', 163), ('continue', 164), ('fraction', 165), ('solution', 166), ('problem', 167), ('unsolvable', 168), ('johann', 169), ('carl', 170), ('gauss', 171), ('german', 172), ('fields', 173), ('sometimes', 174), ('refer', 175), ('princeps', 176), ('mathematicorum', 177), ('greatest', 178), ('since', 179), ('antiquity', 180), ('exceptional', 181), ('influence', 182), ('rank', 183), ('among', 184), (\"history's\", 185), ('paul', 186), ('erdős', 187), ('renowned', 188), ('hungarian', 189), ('prolific', 190), ('producer', 191), ('conjecture', 192), ('know', 193), ('social', 194), ('practice', 195), ('eccentric', 196), ('lifestyle', 197), ('devote', 198), ('waking', 199), ('hours', 200), ('even', 201), ('later', 202), ('years—indeed', 203), ('death', 204), ('come', 205), ('solve', 206), ('geometry', 207), ('conference', 208), ('warsaw', 209), ('alexander', 210), ('grothendieck', 211), ('become', 212), ('leading', 213), ('creation', 214), ('algebraic', 215), ('research', 216), ('extend', 217), ('scope', 218), ('field', 219), ('add', 220), ('elements', 221), ('commutative', 222), ('algebra', 223), ('homological', 224), ('sheaf', 225), ('category', 226), ('so-called', 227), ('relative', 228), ('perspective', 229), ('revolutionary', 230), ('advance', 231), ('area', 232), ('évariste', 233), ('galois', 234), ('political', 235), ('activist', 236), ('still', 237), ('teens', 238), ('able', 239), ('determine', 240), ('necessary', 241), ('sufficient', 242), ('condition', 243), ('polynomial', 244), ('solvable', 245), ('radical', 246), ('thereby', 247), ('solving', 248), ('standing', 249), ('350', 250), ('lay', 251), ('group', 252), ('two', 253), ('major', 254), ('abstract', 255), ('subfield', 256), ('connection', 257), ('die', 258), ('wound', 259), ('suffer', 260), ('duel', 261)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NZ1lyztztmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2ea73d8a-3905-4738-9198-887cb452e0c6"
      },
      "source": [
        "# TF-IDF\n",
        "def tfidf_vectorizer(docs):\n",
        "  def tf(word2id, doc):\n",
        "    term_counts = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      term_counts[word2id[term]] = doc.count(term)\n",
        "    tf_values = list(map(lambda x: x/sum(term_counts), term_counts))\n",
        "    return tf_values\n",
        "  \n",
        "  def idf(word2id, docs):\n",
        "    idf = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      idf[word2id[term]] = np.log(len(docs) / sum([bool(term in doc) for doc in docs]))\n",
        "    return idf\n",
        "  \n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "  \n",
        "  return [[_tf*_idf for _tf, _idf in zip(tf(word2id, doc), idf(word2id, docs))] for doc in docs], word2id\n",
        "\n",
        "tfidf_vector, word2id = tfidf_vectorizer(preprocessed_docs)\n",
        "print(tfidf_vector)\n",
        "print(word2id.items())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0742769384836789, 0.0742769384836789, 0.0, 0.0742769384836789, 0.0, 0.03883783239761084, 0.0742769384836789, 0.0742769384836789, 0.051917352014003236, 0.0742769384836789, 0.029557765544327583, 0.051917352014003236, 0.051917352014003236, 0.0742769384836789, 0.03883783239761084, 0.10383470402800647, 0.016478245927935183, 0.051917352014003236, 0.051917352014003236, 0.0742769384836789, 0.04471917293935131, 0.03883783239761084, 0.0742769384836789, 0.051917352014003236, 0.029557765544327583, 0.0742769384836789, 0.0742769384836789, 0.051917352014003236, 0.051917352014003236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08047189562170502, 0.08047189562170502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1151292546497023, 0.1151292546497023, 0.1151292546497023, 0.04581453659370776, 0.1151292546497023, 0.1151292546497023, 0.1151292546497023, 0.08047189562170502, 0.1151292546497023, 0.1151292546497023, 0.1151292546497023, 0.1151292546497023, 0.08047189562170502, 0.08047189562170502, 0.1151292546497023, 0.1151292546497023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.026754951207243027, 0.0, 0.0, 0.0, 0.0, 0.020362016263870113, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026754951207243027, 0.0, 0.0, 0.020362016263870113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020362016263870113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05116855762208991, 0.10233711524417982, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.07153057388596001, 0.05116855762208991, 0.05116855762208991, 0.03576528694298001, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.03576528694298001, 0.05116855762208991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028666019150617526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02181644599700369, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05482345459509633, 0.10964690919019265, 0.03831995029605, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.03831995029605, 0.03831995029605, 0.05482345459509633, 0.16447036378528898, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05733203830123505, 0.05482345459509633, 0.05482345459509633, 0.03831995029605, 0.05482345459509633, 0.03831995029605, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.03831995029605, 0.05482345459509633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0670599130180875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010642200495124807, 0.0, 0.0, 0.0, 0.014440566261665526, 0.0, 0.0, 0.03352995650904375, 0.0, 0.0, 0.0, 0.03352995650904375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03352995650904375, 0.0, 0.0, 0.0, 0.03352995650904375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025082766756790335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04797052277070929, 0.03352995650904375, 0.09594104554141858, 0.04797052277070929, 0.04797052277070929, 0.025082766756790335, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.03352995650904375, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.025082766756790335, 0.025082766756790335, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.04797052277070929, 0.025082766756790335, 0.04797052277070929, 0.04797052277070929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027766385814368338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015479564356545173, 0.0, 0.0, 0.0, 0.02100446001696804, 0.0, 0.0, 0.0, 0.027766385814368338, 0.0, 0.0, 0.0, 0.048770845831336375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048770845831336375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03648402437351322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.048770845831336375, 0.06977530584830442, 0.09754169166267275, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.06977530584830442, 0.03648402437351322, 0.06977530584830442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.03439922298074103, 0.0, 0.0, 0.0, 0.0, 0.02617973519640443, 0.0, 0.04598394035526001, 0.0, 0.06879844596148206, 0.0, 0.029190035643770897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02617973519640443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09196788071052002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04598394035526001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04598394035526001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06578814551411559, 0.06578814551411559, 0.13157629102823118, 0.06578814551411559, 0.13157629102823118, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.04598394035526001, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.06578814551411559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027612195879242744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0325398055223226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0325398055223226, 0.0325398055223226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04349832195767839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0325398055223226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.12446405908075925, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.062232029540379624, 0.04349832195767839, 0.062232029540379624, 0.062232029540379624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05733203830123505, 0.0, 0.012162514851571207, 0.0, 0.0, 0.0, 0.03300700859809263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028666019150617526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028666019150617526, 0.028666019150617526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028666019150617526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831995029605, 0.0, 0.0, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.0766399005921, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.05482345459509633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.03080654135821979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020362016263870113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576528694298001, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026754951207243027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026754951207243027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576528694298001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05116855762208991, 0.15350567286626973, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991, 0.05116855762208991]]\n",
            "dict_items([('leonhard', 0), ('euler', 1), ('wa', 2), ('swiss', 3), ('mathematician', 4), ('physicist', 5), ('astronomer', 6), ('geographer', 7), ('logician', 8), ('engineer', 9), ('make', 10), ('important', 11), ('influential', 12), ('discovery', 13), ('many', 14), ('branch', 15), ('mathematics', 16), ('infinitesimal', 17), ('calculus', 18), ('graph', 19), ('theory', 20), ('also', 21), ('making', 22), ('pioneer', 23), ('contribution', 24), ('several', 25), ('topology', 26), ('analytic', 27), ('number', 28), ('pierre', 29), ('de', 30), ('fermat', 31), ('french', 32), ('lawyer', 33), ('parlement', 34), ('toulouse', 35), ('france', 36), ('given', 37), ('credit', 38), ('early', 39), ('development', 40), ('led', 41), ('include', 42), ('technique', 43), ('adequality', 44), ('blaise', 45), ('pascal', 46), ('inventor', 47), ('writer', 48), ('catholic', 49), ('theologian', 50), ('child', 51), ('prodigy', 52), ('educate', 53), ('father', 54), ('tax', 55), ('collector', 56), ('rouen', 57), (\"pascal's\", 58), ('earliest', 59), ('work', 60), ('natural', 61), ('apply', 62), ('science', 63), ('study', 64), ('fluid', 65), ('clarify', 66), ('concept', 67), ('pressure', 68), ('vacuum', 69), ('generalise', 70), ('evangelista', 71), ('torricelli', 72), ('write', 73), ('defence', 74), ('scientific', 75), ('method', 76), ('rené', 77), ('descartes', 78), ('philosopher', 79), ('scientist', 80), ('native', 81), ('kingdom', 82), ('spend', 83), ('20', 84), ('years', 85), ('life', 86), ('dutch', 87), ('republic', 88), ('serving', 89), ('state', 90), ('army', 91), ('maurice', 92), ('nassau', 93), ('prince', 94), ('orange', 95), ('stadtholder', 96), ('unite', 97), ('province', 98), ('one', 99), ('notable', 100), ('intellectual', 101), ('figure', 102), ('golden', 103), ('age', 104), ('widely', 105), ('regard', 106), ('founder', 107), ('modern', 108), ('philosophy', 109), ('kurt', 110), ('friedrich', 111), ('gödel', 112), ('austro-hungarian-born', 113), ('austrian', 114), ('consider', 115), ('along', 116), ('aristotle', 117), ('gottlob', 118), ('frege', 119), ('significant', 120), ('history', 121), ('immense', 122), ('effect', 123), ('upon', 124), ('philosophical', 125), ('thinking', 126), ('20th', 127), ('century', 128), ('time', 129), ('others', 130), ('bertrand', 131), ('russell', 132), ('alfred', 133), ('north', 134), ('whitehead', 135), ('david', 136), ('hilbert', 137), ('analyze', 138), ('use', 139), ('logic', 140), ('set', 141), ('understand', 142), ('foundation', 143), ('georg', 144), ('cantor', 145), ('srinivasa', 146), ('ramanujan', 147), ('frs', 148), ('indian', 149), ('live', 150), ('british', 151), ('rule', 152), ('india', 153), ('though', 154), ('almost', 155), ('formal', 156), ('training', 157), ('pure', 158), ('substantial', 159), ('mathematical', 160), ('analysis', 161), ('infinite', 162), ('series', 163), ('continue', 164), ('fraction', 165), ('solution', 166), ('problem', 167), ('unsolvable', 168), ('johann', 169), ('carl', 170), ('gauss', 171), ('german', 172), ('fields', 173), ('sometimes', 174), ('refer', 175), ('princeps', 176), ('mathematicorum', 177), ('greatest', 178), ('since', 179), ('antiquity', 180), ('exceptional', 181), ('influence', 182), ('rank', 183), ('among', 184), (\"history's\", 185), ('paul', 186), ('erdős', 187), ('renowned', 188), ('hungarian', 189), ('prolific', 190), ('producer', 191), ('conjecture', 192), ('know', 193), ('social', 194), ('practice', 195), ('eccentric', 196), ('lifestyle', 197), ('devote', 198), ('waking', 199), ('hours', 200), ('even', 201), ('later', 202), ('years—indeed', 203), ('death', 204), ('come', 205), ('solve', 206), ('geometry', 207), ('conference', 208), ('warsaw', 209), ('alexander', 210), ('grothendieck', 211), ('become', 212), ('leading', 213), ('creation', 214), ('algebraic', 215), ('research', 216), ('extend', 217), ('scope', 218), ('field', 219), ('add', 220), ('elements', 221), ('commutative', 222), ('algebra', 223), ('homological', 224), ('sheaf', 225), ('category', 226), ('so-called', 227), ('relative', 228), ('perspective', 229), ('revolutionary', 230), ('advance', 231), ('area', 232), ('évariste', 233), ('galois', 234), ('political', 235), ('activist', 236), ('still', 237), ('teens', 238), ('able', 239), ('determine', 240), ('necessary', 241), ('sufficient', 242), ('condition', 243), ('polynomial', 244), ('solvable', 245), ('radical', 246), ('thereby', 247), ('solving', 248), ('standing', 249), ('350', 250), ('lay', 251), ('group', 252), ('two', 253), ('major', 254), ('abstract', 255), ('subfield', 256), ('connection', 257), ('die', 258), ('wound', 259), ('suffer', 260), ('duel', 261)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHzw3dPh1dp-",
        "colab_type": "text"
      },
      "source": [
        "Calculate Similarity (Vector Based)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccq7EdDj3Ft1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ユークリッド距離\n",
        "def euclidean_distance(list_a, list_b):\n",
        "  diff_vec = np.array(list_a) - np.array(list_b)\n",
        "  return np.linalg.norm(diff_vec)\n",
        "\n",
        "# コサイン類似度\n",
        "def cosine_similarity(list_a, list_b):\n",
        "  inner_prod = np.array(list_a).dot(np.array(list_b))\n",
        "  norm_a = np.linalg.norm(list_a)\n",
        "  norm_b = np.linalg.norm(list_b)\n",
        "  try:\n",
        "      return inner_prod / (norm_a*norm_b)\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwv1Sohb1iTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_similarity(vec, func_similarity):\n",
        "  start_index = 0\n",
        "  for i in range(start_index, len(documents)-1):\n",
        "    print(\"-\"*20)\n",
        "    for j in range(i+1, len(documents)):\n",
        "      print(\"similarity(doc\" + str(i+1) + \", doc\"+str(j+1)+\") = \" + str(func_similarity(vec[i], vec[j])))\n",
        "  start_index += 1"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RNHnJrw4Aye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85242128-f037-45f4-9f78-17e6eba52243"
      },
      "source": [
        "print(\"BoW * Euclidean distance\")\n",
        "calc_similarity(bow_vec, euclidean_distance)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TF-IDF * Euclidean distance\")\n",
        "calc_similarity(tfidf_vector, euclidean_distance)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"BoW * Cosine Similarity\")\n",
        "calc_similarity(bow_vec, cosine_similarity)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TF-IDF * Cosine Similarity\")\n",
        "calc_similarity(tfidf_vector, cosine_similarity)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BoW * Euclidean distance\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 6.855654600401044\n",
            "similarity(doc1, doc3) = 8.717797887081348\n",
            "similarity(doc1, doc4) = 9.0\n",
            "similarity(doc1, doc5) = 8.306623862918075\n",
            "similarity(doc1, doc6) = 7.3484692283495345\n",
            "similarity(doc1, doc7) = 7.874007874011811\n",
            "similarity(doc1, doc8) = 8.366600265340756\n",
            "similarity(doc1, doc9) = 8.06225774829855\n",
            "similarity(doc1, doc10) = 8.48528137423857\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 8.306623862918075\n",
            "similarity(doc2, doc4) = 8.0\n",
            "similarity(doc2, doc5) = 8.246211251235321\n",
            "similarity(doc2, doc6) = 7.0\n",
            "similarity(doc2, doc7) = 7.937253933193772\n",
            "similarity(doc2, doc8) = 7.681145747868608\n",
            "similarity(doc2, doc9) = 7.874007874011811\n",
            "similarity(doc2, doc10) = 8.18535277187245\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 9.9498743710662\n",
            "similarity(doc3, doc5) = 10.04987562112089\n",
            "similarity(doc3, doc6) = 9.055385138137417\n",
            "similarity(doc3, doc7) = 9.38083151964686\n",
            "similarity(doc3, doc8) = 9.055385138137417\n",
            "similarity(doc3, doc9) = 9.9498743710662\n",
            "similarity(doc3, doc10) = 9.591663046625438\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 9.695359714832659\n",
            "similarity(doc4, doc6) = 9.1104335791443\n",
            "similarity(doc4, doc7) = 9.746794344808963\n",
            "similarity(doc4, doc8) = 9.327379053088816\n",
            "similarity(doc4, doc9) = 9.591663046625438\n",
            "similarity(doc4, doc10) = 9.643650760992955\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 8.774964387392123\n",
            "similarity(doc5, doc7) = 9.327379053088816\n",
            "similarity(doc5, doc8) = 9.0\n",
            "similarity(doc5, doc9) = 9.055385138137417\n",
            "similarity(doc5, doc10) = 9.746794344808963\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 8.366600265340756\n",
            "similarity(doc6, doc8) = 8.0\n",
            "similarity(doc6, doc9) = 8.306623862918075\n",
            "similarity(doc6, doc10) = 8.831760866327848\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 8.602325267042627\n",
            "similarity(doc7, doc9) = 8.54400374531753\n",
            "similarity(doc7, doc10) = 9.797958971132712\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 8.660254037844387\n",
            "similarity(doc8, doc10) = 9.273618495495704\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 9.1104335791443\n",
            "============================================================\n",
            "TF-IDF * Euclidean distance\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 0.5276356911279416\n",
            "similarity(doc1, doc3) = 0.4321013444670544\n",
            "similarity(doc1, doc4) = 0.4747851940961402\n",
            "similarity(doc1, doc5) = 0.42030536881725167\n",
            "similarity(doc1, doc6) = 0.4579821690666793\n",
            "similarity(doc1, doc7) = 0.45277122825730504\n",
            "similarity(doc1, doc8) = 0.4584123553633701\n",
            "similarity(doc1, doc9) = 0.42707042107976606\n",
            "similarity(doc1, doc10) = 0.4458006484205032\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 0.5357998262167599\n",
            "similarity(doc2, doc4) = 0.5580675320635031\n",
            "similarity(doc2, doc5) = 0.5330884372926673\n",
            "similarity(doc2, doc6) = 0.5518986599032526\n",
            "similarity(doc2, doc7) = 0.5601855381125594\n",
            "similarity(doc2, doc8) = 0.5504634458183818\n",
            "similarity(doc2, doc9) = 0.5253438238585888\n",
            "similarity(doc2, doc10) = 0.546821016464453\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 0.46804005817356426\n",
            "similarity(doc3, doc5) = 0.42855919240084933\n",
            "similarity(doc3, doc6) = 0.4604976587157402\n",
            "similarity(doc3, doc7) = 0.4529177082335229\n",
            "similarity(doc3, doc8) = 0.4526456910540957\n",
            "similarity(doc3, doc9) = 0.4289890532343018\n",
            "similarity(doc3, doc10) = 0.44363413615295816\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 0.45964564209739434\n",
            "similarity(doc4, doc6) = 0.4949526793338431\n",
            "similarity(doc4, doc7) = 0.4963310349524386\n",
            "similarity(doc4, doc8) = 0.4814722396729705\n",
            "similarity(doc4, doc9) = 0.4569644145127749\n",
            "similarity(doc4, doc10) = 0.4736074726056469\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 0.45474096055657354\n",
            "similarity(doc5, doc7) = 0.4518112200646711\n",
            "similarity(doc5, doc8) = 0.44117950767221814\n",
            "similarity(doc5, doc9) = 0.41509438337241955\n",
            "similarity(doc5, doc10) = 0.44244916599655326\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 0.4851483053215215\n",
            "similarity(doc6, doc8) = 0.4654754508589753\n",
            "similarity(doc6, doc9) = 0.4471389840632588\n",
            "similarity(doc6, doc10) = 0.47223402698005157\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 0.4776366300066049\n",
            "similarity(doc7, doc9) = 0.4435868292379024\n",
            "similarity(doc7, doc10) = 0.4770929928550185\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 0.4363002237175467\n",
            "similarity(doc8, doc10) = 0.46376577071304165\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 0.4323351738615729\n",
            "============================================================\n",
            "BoW * Cosine Similarity\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 0.15118578920369088\n",
            "similarity(doc1, doc3) = 0.2164218276749025\n",
            "similarity(doc1, doc4) = 0.07032108464077431\n",
            "similarity(doc1, doc5) = 0.21096325392232293\n",
            "similarity(doc1, doc6) = 0.22857142857142856\n",
            "similarity(doc1, doc7) = 0.2840286409986905\n",
            "similarity(doc1, doc8) = 0.16903085094570333\n",
            "similarity(doc1, doc9) = 0.23904572186687872\n",
            "similarity(doc1, doc10) = 0.20512903762734833\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 0.17177950029416048\n",
            "similarity(doc2, doc4) = 0.12403473458920847\n",
            "similarity(doc2, doc5) = 0.062017367294604234\n",
            "similarity(doc2, doc6) = 0.11338934190276816\n",
            "similarity(doc2, doc7) = 0.12524485821702988\n",
            "similarity(doc2, doc8) = 0.15971914124998496\n",
            "similarity(doc2, doc9) = 0.12649110640673517\n",
            "similarity(doc2, doc10) = 0.12060453783110543\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 0.12428864423997614\n",
            "similarity(doc3, doc5) = 0.10653312363426526\n",
            "similarity(doc3, doc6) = 0.15149527937243176\n",
            "similarity(doc3, doc7) = 0.21514499158934372\n",
            "similarity(doc3, doc8) = 0.25607375986579195\n",
            "similarity(doc3, doc9) = 0.10864289525102223\n",
            "similarity(doc3, doc10) = 0.20717387241835467\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 0.09615384615384617\n",
            "similarity(doc4, doc6) = 0.04688072309384954\n",
            "similarity(doc4, doc7) = 0.07767356373806174\n",
            "similarity(doc4, doc8) = 0.1386750490563073\n",
            "similarity(doc4, doc9) = 0.09805806756909202\n",
            "similarity(doc4, doc10) = 0.13089257860118403\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 0.11720180773462385\n",
            "similarity(doc5, doc7) = 0.15534712747612348\n",
            "similarity(doc5, doc8) = 0.19810721293758182\n",
            "similarity(doc5, doc9) = 0.19611613513818404\n",
            "similarity(doc5, doc10) = 0.11219363880101486\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 0.18935242733246035\n",
            "similarity(doc6, doc8) = 0.2414726442081476\n",
            "similarity(doc6, doc9) = 0.19123657749350298\n",
            "similarity(doc6, doc10) = 0.13675269175156554\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 0.2600520156052018\n",
            "similarity(doc7, doc9) = 0.27724131203346875\n",
            "similarity(doc7, doc10) = 0.09440686400617013\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 0.24243661069253056\n",
            "similarity(doc8, doc10) = 0.1733656789191194\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 0.20976176963403032\n",
            "============================================================\n",
            "TF-IDF * Cosine Similarity\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 0.05959516739262469\n",
            "similarity(doc1, doc3) = 0.05219859068651274\n",
            "similarity(doc1, doc4) = 0.009838252172827308\n",
            "similarity(doc1, doc5) = 0.08112247045278102\n",
            "similarity(doc1, doc6) = 0.04884282372422781\n",
            "similarity(doc1, doc7) = 0.07621415267599321\n",
            "similarity(doc1, doc8) = 0.004314764200522996\n",
            "similarity(doc1, doc9) = 0.041138798319532856\n",
            "similarity(doc1, doc10) = 0.04875781695263602\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 0.006865020288671431\n",
            "similarity(doc2, doc4) = 0.02614040592638503\n",
            "similarity(doc2, doc5) = 0.0\n",
            "similarity(doc2, doc6) = 0.02587150246127916\n",
            "similarity(doc2, doc7) = 0.0\n",
            "similarity(doc2, doc8) = 0.0\n",
            "similarity(doc2, doc9) = 0.023546514538180918\n",
            "similarity(doc2, doc10) = 0.0064722468022745516\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 0.01104331464556307\n",
            "similarity(doc3, doc5) = 0.012894687453937884\n",
            "similarity(doc3, doc6) = 0.010616063400680683\n",
            "similarity(doc3, doc7) = 0.049248922353124204\n",
            "similarity(doc3, doc8) = 0.0\n",
            "similarity(doc3, doc9) = 0.0\n",
            "similarity(doc3, doc10) = 0.029375882701137536\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 0.025470932347355195\n",
            "similarity(doc4, doc6) = 0.0\n",
            "similarity(doc4, doc7) = 0.0\n",
            "similarity(doc4, doc8) = 0.0158798353505203\n",
            "similarity(doc4, doc9) = 0.027784886582093174\n",
            "similarity(doc4, doc10) = 0.03916217760175658\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 0.01332269437843755\n",
            "similarity(doc5, doc7) = 0.03250782978867855\n",
            "similarity(doc5, doc8) = 0.02752926604070102\n",
            "similarity(doc5, doc9) = 0.038851300742014476\n",
            "similarity(doc5, doc10) = 0.011312925196190322\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 0.01593537463683535\n",
            "similarity(doc6, doc8) = 0.051339408386223646\n",
            "similarity(doc6, doc9) = 0.03698240027739047\n",
            "similarity(doc6, doc10) = 0.014367442600872563\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 0.007024130665455183\n",
            "similarity(doc7, doc9) = 0.05871254516383112\n",
            "similarity(doc7, doc10) = 0.0\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 0.039272997473072266\n",
            "similarity(doc8, doc10) = 0.00803102478074372\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 0.046392733245248924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRolrWz8-WVU",
        "colab_type": "text"
      },
      "source": [
        "Calculate Similarity (Set Based)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyZzNPwycmtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dice Similarity\n",
        "def dice_similarity(list_a, list_b):\n",
        "  num_intersection =  len(set.intersection(set(list_a), set(list_b)))\n",
        "  sum_nums = len(set(list_a)) + len(set(list_b))\n",
        "  try:\n",
        "    return 2 * num_intersection / sum_nums\n",
        "  except ZeroDivisionError:\n",
        "    return 1.0\n",
        "\n",
        "def simpson_similarity(list_a, list_b):\n",
        "  num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
        "  min_num = min(len(set(list_a)), len(set(list_b)))\n",
        "  try:\n",
        "    return num_intersection / min_num\n",
        "  except ZeroDivisionError:\n",
        "    if num_intersection == 0:\n",
        "      return 1.0\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEVWUNLm-_kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_similarity_set(sets, func_similarity):\n",
        "  start_index = 0\n",
        "  for i in range(start_index, len(documents)-1):\n",
        "    print(\"-\"*20)\n",
        "    for j in range(i+1, len(documents)):\n",
        "      print(\"similarity(doc\" + str(i+1) + \", doc\"+str(j+1)+\") = \" + str(func_similarity(sets[i], sets[j])))\n",
        "  start_index += 1"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgRbIzakA8fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fea5707-59c3-4421-82d0-18855fd28385"
      },
      "source": [
        "print(\"Dice Similarity\")\n",
        "calc_similarity(preprocessed_docs, dice_similarity)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Simpson Similarity\")\n",
        "calc_similarity(preprocessed_docs, simpson_similarity)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice Similarity\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 0.16326530612244897\n",
            "similarity(doc1, doc3) = 0.2028985507246377\n",
            "similarity(doc1, doc4) = 0.08955223880597014\n",
            "similarity(doc1, doc5) = 0.18666666666666668\n",
            "similarity(doc1, doc6) = 0.22950819672131148\n",
            "similarity(doc1, doc7) = 0.2807017543859649\n",
            "similarity(doc1, doc8) = 0.09836065573770492\n",
            "similarity(doc1, doc9) = 0.14925373134328357\n",
            "similarity(doc1, doc10) = 0.11428571428571428\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 0.1\n",
            "similarity(doc2, doc4) = 0.13793103448275862\n",
            "similarity(doc2, doc5) = 0.06060606060606061\n",
            "similarity(doc2, doc6) = 0.11538461538461539\n",
            "similarity(doc2, doc7) = 0.08333333333333333\n",
            "similarity(doc2, doc8) = 0.07692307692307693\n",
            "similarity(doc2, doc9) = 0.10344827586206896\n",
            "similarity(doc2, doc10) = 0.09836065573770492\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 0.10256410256410256\n",
            "similarity(doc3, doc5) = 0.06976744186046512\n",
            "similarity(doc3, doc6) = 0.1111111111111111\n",
            "similarity(doc3, doc7) = 0.17647058823529413\n",
            "similarity(doc3, doc8) = 0.05555555555555555\n",
            "similarity(doc3, doc9) = 0.05128205128205128\n",
            "similarity(doc3, doc10) = 0.09876543209876543\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 0.09523809523809523\n",
            "similarity(doc4, doc6) = 0.05714285714285714\n",
            "similarity(doc4, doc7) = 0.06060606060606061\n",
            "similarity(doc4, doc8) = 0.08571428571428572\n",
            "similarity(doc4, doc9) = 0.10526315789473684\n",
            "similarity(doc4, doc10) = 0.1518987341772152\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 0.1282051282051282\n",
            "similarity(doc5, doc7) = 0.13513513513513514\n",
            "similarity(doc5, doc8) = 0.15384615384615385\n",
            "similarity(doc5, doc9) = 0.19047619047619047\n",
            "similarity(doc5, doc10) = 0.09195402298850575\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 0.16666666666666666\n",
            "similarity(doc6, doc8) = 0.15625\n",
            "similarity(doc6, doc9) = 0.17142857142857143\n",
            "similarity(doc6, doc10) = 0.1095890410958904\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 0.1\n",
            "similarity(doc7, doc9) = 0.15151515151515152\n",
            "similarity(doc7, doc10) = 0.057971014492753624\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 0.17142857142857143\n",
            "similarity(doc8, doc10) = 0.0821917808219178\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 0.12658227848101267\n",
            "============================================================\n",
            "Simpson Similarity\n",
            "--------------------\n",
            "similarity(doc1, doc2) = 0.2\n",
            "similarity(doc1, doc3) = 0.2413793103448276\n",
            "similarity(doc1, doc4) = 0.10344827586206896\n",
            "similarity(doc1, doc5) = 0.2413793103448276\n",
            "similarity(doc1, doc6) = 0.2413793103448276\n",
            "similarity(doc1, doc7) = 0.2857142857142857\n",
            "similarity(doc1, doc8) = 0.10344827586206896\n",
            "similarity(doc1, doc9) = 0.1724137931034483\n",
            "similarity(doc1, doc10) = 0.13793103448275862\n",
            "--------------------\n",
            "similarity(doc2, doc3) = 0.15\n",
            "similarity(doc2, doc4) = 0.2\n",
            "similarity(doc2, doc5) = 0.1\n",
            "similarity(doc2, doc6) = 0.15\n",
            "similarity(doc2, doc7) = 0.1\n",
            "similarity(doc2, doc8) = 0.1\n",
            "similarity(doc2, doc9) = 0.15\n",
            "similarity(doc2, doc10) = 0.15\n",
            "--------------------\n",
            "similarity(doc3, doc4) = 0.10526315789473684\n",
            "similarity(doc3, doc5) = 0.075\n",
            "similarity(doc3, doc6) = 0.125\n",
            "similarity(doc3, doc7) = 0.21428571428571427\n",
            "similarity(doc3, doc8) = 0.0625\n",
            "similarity(doc3, doc9) = 0.05263157894736842\n",
            "similarity(doc3, doc10) = 0.1\n",
            "--------------------\n",
            "similarity(doc4, doc5) = 0.10526315789473684\n",
            "similarity(doc4, doc6) = 0.0625\n",
            "similarity(doc4, doc7) = 0.07142857142857142\n",
            "similarity(doc4, doc8) = 0.09375\n",
            "similarity(doc4, doc9) = 0.10526315789473684\n",
            "similarity(doc4, doc10) = 0.15789473684210525\n",
            "--------------------\n",
            "similarity(doc5, doc6) = 0.15625\n",
            "similarity(doc5, doc7) = 0.17857142857142858\n",
            "similarity(doc5, doc8) = 0.1875\n",
            "similarity(doc5, doc9) = 0.21052631578947367\n",
            "similarity(doc5, doc10) = 0.0975609756097561\n",
            "--------------------\n",
            "similarity(doc6, doc7) = 0.17857142857142858\n",
            "similarity(doc6, doc8) = 0.15625\n",
            "similarity(doc6, doc9) = 0.1875\n",
            "similarity(doc6, doc10) = 0.125\n",
            "--------------------\n",
            "similarity(doc7, doc8) = 0.10714285714285714\n",
            "similarity(doc7, doc9) = 0.17857142857142858\n",
            "similarity(doc7, doc10) = 0.07142857142857142\n",
            "--------------------\n",
            "similarity(doc8, doc9) = 0.1875\n",
            "similarity(doc8, doc10) = 0.09375\n",
            "--------------------\n",
            "similarity(doc9, doc10) = 0.13157894736842105\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}